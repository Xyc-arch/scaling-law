{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 100.0,
  "eval_steps": 500,
  "global_step": 222700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.224517287831163,
      "grad_norm": 1.9122121334075928,
      "learning_rate": 4.9887741356084424e-05,
      "loss": 0.6671,
      "step": 500
    },
    {
      "epoch": 0.449034575662326,
      "grad_norm": 2.418445348739624,
      "learning_rate": 4.9775482712168845e-05,
      "loss": 0.5649,
      "step": 1000
    },
    {
      "epoch": 0.673551863493489,
      "grad_norm": 1.6910632848739624,
      "learning_rate": 4.966322406825326e-05,
      "loss": 0.5519,
      "step": 1500
    },
    {
      "epoch": 0.898069151324652,
      "grad_norm": 1.6923290491104126,
      "learning_rate": 4.9550965424337673e-05,
      "loss": 0.5456,
      "step": 2000
    },
    {
      "epoch": 1.122586439155815,
      "grad_norm": 1.5534541606903076,
      "learning_rate": 4.9438706780422095e-05,
      "loss": 0.5416,
      "step": 2500
    },
    {
      "epoch": 1.347103726986978,
      "grad_norm": 1.2630425691604614,
      "learning_rate": 4.9326448136506516e-05,
      "loss": 0.5384,
      "step": 3000
    },
    {
      "epoch": 1.5716210148181409,
      "grad_norm": 0.9742903709411621,
      "learning_rate": 4.921418949259094e-05,
      "loss": 0.5366,
      "step": 3500
    },
    {
      "epoch": 1.7961383026493039,
      "grad_norm": 1.202918291091919,
      "learning_rate": 4.910193084867535e-05,
      "loss": 0.5342,
      "step": 4000
    },
    {
      "epoch": 2.020655590480467,
      "grad_norm": 0.774040162563324,
      "learning_rate": 4.8989672204759766e-05,
      "loss": 0.5324,
      "step": 4500
    },
    {
      "epoch": 2.24517287831163,
      "grad_norm": 0.7363203763961792,
      "learning_rate": 4.887741356084419e-05,
      "loss": 0.5308,
      "step": 5000
    },
    {
      "epoch": 2.469690166142793,
      "grad_norm": 0.7795583009719849,
      "learning_rate": 4.876515491692861e-05,
      "loss": 0.53,
      "step": 5500
    },
    {
      "epoch": 2.694207453973956,
      "grad_norm": 0.8490092754364014,
      "learning_rate": 4.865289627301303e-05,
      "loss": 0.5287,
      "step": 6000
    },
    {
      "epoch": 2.9187247418051188,
      "grad_norm": 0.6816584467887878,
      "learning_rate": 4.8540637629097443e-05,
      "loss": 0.528,
      "step": 6500
    },
    {
      "epoch": 3.143242029636282,
      "grad_norm": 0.7386666536331177,
      "learning_rate": 4.842837898518186e-05,
      "loss": 0.5268,
      "step": 7000
    },
    {
      "epoch": 3.367759317467445,
      "grad_norm": 0.6322154402732849,
      "learning_rate": 4.831612034126628e-05,
      "loss": 0.5259,
      "step": 7500
    },
    {
      "epoch": 3.592276605298608,
      "grad_norm": 0.7942122220993042,
      "learning_rate": 4.82038616973507e-05,
      "loss": 0.5255,
      "step": 8000
    },
    {
      "epoch": 3.816793893129771,
      "grad_norm": 0.7765156030654907,
      "learning_rate": 4.809160305343512e-05,
      "loss": 0.5248,
      "step": 8500
    },
    {
      "epoch": 4.041311180960934,
      "grad_norm": 0.7113147974014282,
      "learning_rate": 4.7979344409519536e-05,
      "loss": 0.5242,
      "step": 9000
    },
    {
      "epoch": 4.265828468792097,
      "grad_norm": 0.5943962931632996,
      "learning_rate": 4.786708576560395e-05,
      "loss": 0.5238,
      "step": 9500
    },
    {
      "epoch": 4.49034575662326,
      "grad_norm": 0.6853864192962646,
      "learning_rate": 4.775482712168837e-05,
      "loss": 0.5227,
      "step": 10000
    },
    {
      "epoch": 4.714863044454423,
      "grad_norm": 0.6603785753250122,
      "learning_rate": 4.764256847777279e-05,
      "loss": 0.5228,
      "step": 10500
    },
    {
      "epoch": 4.939380332285586,
      "grad_norm": 0.6075482368469238,
      "learning_rate": 4.7530309833857213e-05,
      "loss": 0.5221,
      "step": 11000
    },
    {
      "epoch": 5.163897620116749,
      "grad_norm": 0.596859872341156,
      "learning_rate": 4.741805118994163e-05,
      "loss": 0.5219,
      "step": 11500
    },
    {
      "epoch": 5.388414907947912,
      "grad_norm": 0.6157668828964233,
      "learning_rate": 4.730579254602604e-05,
      "loss": 0.5215,
      "step": 12000
    },
    {
      "epoch": 5.612932195779075,
      "grad_norm": 0.5513584613800049,
      "learning_rate": 4.719353390211046e-05,
      "loss": 0.5208,
      "step": 12500
    },
    {
      "epoch": 5.8374494836102375,
      "grad_norm": 0.57149338722229,
      "learning_rate": 4.7081275258194884e-05,
      "loss": 0.5207,
      "step": 13000
    },
    {
      "epoch": 6.061966771441401,
      "grad_norm": 0.5683155655860901,
      "learning_rate": 4.6969016614279306e-05,
      "loss": 0.5204,
      "step": 13500
    },
    {
      "epoch": 6.286484059272564,
      "grad_norm": 0.5824667811393738,
      "learning_rate": 4.685675797036372e-05,
      "loss": 0.5201,
      "step": 14000
    },
    {
      "epoch": 6.511001347103727,
      "grad_norm": 0.6273301243782043,
      "learning_rate": 4.674449932644814e-05,
      "loss": 0.5198,
      "step": 14500
    },
    {
      "epoch": 6.73551863493489,
      "grad_norm": 0.5101761817932129,
      "learning_rate": 4.6632240682532556e-05,
      "loss": 0.5194,
      "step": 15000
    },
    {
      "epoch": 6.960035922766053,
      "grad_norm": 0.484004408121109,
      "learning_rate": 4.651998203861698e-05,
      "loss": 0.5195,
      "step": 15500
    },
    {
      "epoch": 7.184553210597216,
      "grad_norm": 0.6031347513198853,
      "learning_rate": 4.64077233947014e-05,
      "loss": 0.519,
      "step": 16000
    },
    {
      "epoch": 7.409070498428379,
      "grad_norm": 0.6171324253082275,
      "learning_rate": 4.629546475078581e-05,
      "loss": 0.519,
      "step": 16500
    },
    {
      "epoch": 7.633587786259542,
      "grad_norm": 0.5038177967071533,
      "learning_rate": 4.618320610687023e-05,
      "loss": 0.5187,
      "step": 17000
    },
    {
      "epoch": 7.858105074090705,
      "grad_norm": 0.5439339280128479,
      "learning_rate": 4.607094746295465e-05,
      "loss": 0.5185,
      "step": 17500
    },
    {
      "epoch": 8.082622361921867,
      "grad_norm": 0.4551231861114502,
      "learning_rate": 4.595868881903907e-05,
      "loss": 0.5178,
      "step": 18000
    },
    {
      "epoch": 8.307139649753031,
      "grad_norm": 0.5187365412712097,
      "learning_rate": 4.584643017512349e-05,
      "loss": 0.518,
      "step": 18500
    },
    {
      "epoch": 8.531656937584193,
      "grad_norm": 0.5122042298316956,
      "learning_rate": 4.5734171531207904e-05,
      "loss": 0.5178,
      "step": 19000
    },
    {
      "epoch": 8.756174225415357,
      "grad_norm": 0.4568096995353699,
      "learning_rate": 4.5621912887292326e-05,
      "loss": 0.5177,
      "step": 19500
    },
    {
      "epoch": 8.98069151324652,
      "grad_norm": 0.405322790145874,
      "learning_rate": 4.550965424337674e-05,
      "loss": 0.5174,
      "step": 20000
    },
    {
      "epoch": 9.205208801077683,
      "grad_norm": 0.38240355253219604,
      "learning_rate": 4.539739559946116e-05,
      "loss": 0.5172,
      "step": 20500
    },
    {
      "epoch": 9.429726088908845,
      "grad_norm": 0.44301560521125793,
      "learning_rate": 4.528513695554558e-05,
      "loss": 0.517,
      "step": 21000
    },
    {
      "epoch": 9.654243376740009,
      "grad_norm": 0.43381455540657043,
      "learning_rate": 4.5172878311629997e-05,
      "loss": 0.517,
      "step": 21500
    },
    {
      "epoch": 9.878760664571171,
      "grad_norm": 0.42342278361320496,
      "learning_rate": 4.506061966771442e-05,
      "loss": 0.5171,
      "step": 22000
    },
    {
      "epoch": 10.103277952402335,
      "grad_norm": 0.4470076858997345,
      "learning_rate": 4.494836102379883e-05,
      "loss": 0.5166,
      "step": 22500
    },
    {
      "epoch": 10.327795240233497,
      "grad_norm": 0.45034176111221313,
      "learning_rate": 4.483610237988325e-05,
      "loss": 0.5165,
      "step": 23000
    },
    {
      "epoch": 10.552312528064661,
      "grad_norm": 0.4892529547214508,
      "learning_rate": 4.4723843735967674e-05,
      "loss": 0.5165,
      "step": 23500
    },
    {
      "epoch": 10.776829815895823,
      "grad_norm": 0.38282036781311035,
      "learning_rate": 4.461158509205209e-05,
      "loss": 0.5166,
      "step": 24000
    },
    {
      "epoch": 11.001347103726987,
      "grad_norm": 0.49445074796676636,
      "learning_rate": 4.449932644813651e-05,
      "loss": 0.5162,
      "step": 24500
    },
    {
      "epoch": 11.22586439155815,
      "grad_norm": 0.425265908241272,
      "learning_rate": 4.4387067804220924e-05,
      "loss": 0.5161,
      "step": 25000
    },
    {
      "epoch": 11.450381679389313,
      "grad_norm": 0.3942233920097351,
      "learning_rate": 4.4274809160305345e-05,
      "loss": 0.5158,
      "step": 25500
    },
    {
      "epoch": 11.674898967220475,
      "grad_norm": 0.41624051332473755,
      "learning_rate": 4.4162550516389767e-05,
      "loss": 0.516,
      "step": 26000
    },
    {
      "epoch": 11.899416255051639,
      "grad_norm": 0.39701852202415466,
      "learning_rate": 4.405029187247418e-05,
      "loss": 0.5157,
      "step": 26500
    },
    {
      "epoch": 12.123933542882803,
      "grad_norm": 0.40567493438720703,
      "learning_rate": 4.39380332285586e-05,
      "loss": 0.5158,
      "step": 27000
    },
    {
      "epoch": 12.348450830713965,
      "grad_norm": 0.3402322828769684,
      "learning_rate": 4.382577458464302e-05,
      "loss": 0.5154,
      "step": 27500
    },
    {
      "epoch": 12.572968118545129,
      "grad_norm": 0.3932979702949524,
      "learning_rate": 4.371351594072744e-05,
      "loss": 0.5155,
      "step": 28000
    },
    {
      "epoch": 12.79748540637629,
      "grad_norm": 0.48680388927459717,
      "learning_rate": 4.360125729681186e-05,
      "loss": 0.5153,
      "step": 28500
    },
    {
      "epoch": 13.022002694207455,
      "grad_norm": 0.3635004758834839,
      "learning_rate": 4.348899865289627e-05,
      "loss": 0.5152,
      "step": 29000
    },
    {
      "epoch": 13.246519982038617,
      "grad_norm": 0.38646218180656433,
      "learning_rate": 4.3376740008980694e-05,
      "loss": 0.515,
      "step": 29500
    },
    {
      "epoch": 13.47103726986978,
      "grad_norm": 0.38373997807502747,
      "learning_rate": 4.3264481365065115e-05,
      "loss": 0.515,
      "step": 30000
    },
    {
      "epoch": 13.695554557700943,
      "grad_norm": 0.37566229701042175,
      "learning_rate": 4.315222272114953e-05,
      "loss": 0.5147,
      "step": 30500
    },
    {
      "epoch": 13.920071845532107,
      "grad_norm": 0.3896499276161194,
      "learning_rate": 4.3039964077233944e-05,
      "loss": 0.5152,
      "step": 31000
    },
    {
      "epoch": 14.144589133363269,
      "grad_norm": 0.3905036151409149,
      "learning_rate": 4.2927705433318365e-05,
      "loss": 0.5148,
      "step": 31500
    },
    {
      "epoch": 14.369106421194433,
      "grad_norm": 0.4072572886943817,
      "learning_rate": 4.2815446789402786e-05,
      "loss": 0.5148,
      "step": 32000
    },
    {
      "epoch": 14.593623709025595,
      "grad_norm": 0.4284513592720032,
      "learning_rate": 4.270318814548721e-05,
      "loss": 0.5146,
      "step": 32500
    },
    {
      "epoch": 14.818140996856759,
      "grad_norm": 0.45718103647232056,
      "learning_rate": 4.259092950157162e-05,
      "loss": 0.5146,
      "step": 33000
    },
    {
      "epoch": 15.04265828468792,
      "grad_norm": 0.3474765121936798,
      "learning_rate": 4.2478670857656036e-05,
      "loss": 0.5144,
      "step": 33500
    },
    {
      "epoch": 15.267175572519085,
      "grad_norm": 0.3064892292022705,
      "learning_rate": 4.236641221374046e-05,
      "loss": 0.5143,
      "step": 34000
    },
    {
      "epoch": 15.491692860350247,
      "grad_norm": 0.3947952389717102,
      "learning_rate": 4.225415356982488e-05,
      "loss": 0.5144,
      "step": 34500
    },
    {
      "epoch": 15.71621014818141,
      "grad_norm": 0.4164581298828125,
      "learning_rate": 4.21418949259093e-05,
      "loss": 0.5141,
      "step": 35000
    },
    {
      "epoch": 15.940727436012573,
      "grad_norm": 0.4767332375049591,
      "learning_rate": 4.2029636281993714e-05,
      "loss": 0.5142,
      "step": 35500
    },
    {
      "epoch": 16.165244723843735,
      "grad_norm": 0.3579457700252533,
      "learning_rate": 4.191737763807813e-05,
      "loss": 0.5139,
      "step": 36000
    },
    {
      "epoch": 16.3897620116749,
      "grad_norm": 0.34243160486221313,
      "learning_rate": 4.180511899416255e-05,
      "loss": 0.5139,
      "step": 36500
    },
    {
      "epoch": 16.614279299506062,
      "grad_norm": 0.4472857415676117,
      "learning_rate": 4.169286035024697e-05,
      "loss": 0.5139,
      "step": 37000
    },
    {
      "epoch": 16.838796587337225,
      "grad_norm": 0.3328561782836914,
      "learning_rate": 4.158060170633139e-05,
      "loss": 0.5138,
      "step": 37500
    },
    {
      "epoch": 17.063313875168387,
      "grad_norm": 0.31848204135894775,
      "learning_rate": 4.146834306241581e-05,
      "loss": 0.5139,
      "step": 38000
    },
    {
      "epoch": 17.287831162999552,
      "grad_norm": 0.32719501852989197,
      "learning_rate": 4.135608441850022e-05,
      "loss": 0.5134,
      "step": 38500
    },
    {
      "epoch": 17.512348450830714,
      "grad_norm": 0.331728458404541,
      "learning_rate": 4.124382577458464e-05,
      "loss": 0.5135,
      "step": 39000
    },
    {
      "epoch": 17.736865738661876,
      "grad_norm": 0.33128392696380615,
      "learning_rate": 4.113156713066906e-05,
      "loss": 0.5137,
      "step": 39500
    },
    {
      "epoch": 17.96138302649304,
      "grad_norm": 0.3304530084133148,
      "learning_rate": 4.1019308486753484e-05,
      "loss": 0.5139,
      "step": 40000
    },
    {
      "epoch": 18.185900314324204,
      "grad_norm": 0.39844805002212524,
      "learning_rate": 4.0907049842837905e-05,
      "loss": 0.5135,
      "step": 40500
    },
    {
      "epoch": 18.410417602155366,
      "grad_norm": 0.3654329776763916,
      "learning_rate": 4.079479119892232e-05,
      "loss": 0.5132,
      "step": 41000
    },
    {
      "epoch": 18.63493488998653,
      "grad_norm": 0.3324874937534332,
      "learning_rate": 4.0682532555006734e-05,
      "loss": 0.5133,
      "step": 41500
    },
    {
      "epoch": 18.85945217781769,
      "grad_norm": 0.35118186473846436,
      "learning_rate": 4.0570273911091155e-05,
      "loss": 0.5131,
      "step": 42000
    },
    {
      "epoch": 19.083969465648856,
      "grad_norm": 0.3052295446395874,
      "learning_rate": 4.0458015267175576e-05,
      "loss": 0.5134,
      "step": 42500
    },
    {
      "epoch": 19.308486753480018,
      "grad_norm": 0.35034844279289246,
      "learning_rate": 4.034575662326e-05,
      "loss": 0.5131,
      "step": 43000
    },
    {
      "epoch": 19.53300404131118,
      "grad_norm": 0.3454144299030304,
      "learning_rate": 4.023349797934441e-05,
      "loss": 0.5131,
      "step": 43500
    },
    {
      "epoch": 19.757521329142342,
      "grad_norm": 0.31565868854522705,
      "learning_rate": 4.0121239335428826e-05,
      "loss": 0.513,
      "step": 44000
    },
    {
      "epoch": 19.982038616973508,
      "grad_norm": 0.33002662658691406,
      "learning_rate": 4.000898069151325e-05,
      "loss": 0.5129,
      "step": 44500
    },
    {
      "epoch": 20.20655590480467,
      "grad_norm": 0.33868199586868286,
      "learning_rate": 3.989672204759767e-05,
      "loss": 0.5129,
      "step": 45000
    },
    {
      "epoch": 20.431073192635832,
      "grad_norm": 0.32425928115844727,
      "learning_rate": 3.978446340368209e-05,
      "loss": 0.5127,
      "step": 45500
    },
    {
      "epoch": 20.655590480466994,
      "grad_norm": 0.3523624539375305,
      "learning_rate": 3.9672204759766504e-05,
      "loss": 0.513,
      "step": 46000
    },
    {
      "epoch": 20.88010776829816,
      "grad_norm": 0.2926604151725769,
      "learning_rate": 3.955994611585092e-05,
      "loss": 0.5128,
      "step": 46500
    },
    {
      "epoch": 21.104625056129322,
      "grad_norm": 0.3564261496067047,
      "learning_rate": 3.944768747193534e-05,
      "loss": 0.5127,
      "step": 47000
    },
    {
      "epoch": 21.329142343960484,
      "grad_norm": 0.4427412450313568,
      "learning_rate": 3.933542882801976e-05,
      "loss": 0.5126,
      "step": 47500
    },
    {
      "epoch": 21.553659631791646,
      "grad_norm": 0.31352686882019043,
      "learning_rate": 3.922317018410418e-05,
      "loss": 0.5126,
      "step": 48000
    },
    {
      "epoch": 21.778176919622812,
      "grad_norm": 0.32081130146980286,
      "learning_rate": 3.9110911540188596e-05,
      "loss": 0.5128,
      "step": 48500
    },
    {
      "epoch": 22.002694207453974,
      "grad_norm": 0.3930942118167877,
      "learning_rate": 3.899865289627301e-05,
      "loss": 0.5124,
      "step": 49000
    },
    {
      "epoch": 22.227211495285136,
      "grad_norm": 0.3674740791320801,
      "learning_rate": 3.888639425235743e-05,
      "loss": 0.5122,
      "step": 49500
    },
    {
      "epoch": 22.4517287831163,
      "grad_norm": 0.298065721988678,
      "learning_rate": 3.877413560844185e-05,
      "loss": 0.5124,
      "step": 50000
    },
    {
      "epoch": 22.676246070947464,
      "grad_norm": 0.3437361419200897,
      "learning_rate": 3.8661876964526274e-05,
      "loss": 0.5125,
      "step": 50500
    },
    {
      "epoch": 22.900763358778626,
      "grad_norm": 0.29090118408203125,
      "learning_rate": 3.854961832061069e-05,
      "loss": 0.5124,
      "step": 51000
    },
    {
      "epoch": 23.125280646609788,
      "grad_norm": 0.3432565927505493,
      "learning_rate": 3.84373596766951e-05,
      "loss": 0.5121,
      "step": 51500
    },
    {
      "epoch": 23.349797934440954,
      "grad_norm": 0.3776087164878845,
      "learning_rate": 3.8325101032779524e-05,
      "loss": 0.5122,
      "step": 52000
    },
    {
      "epoch": 23.574315222272116,
      "grad_norm": 0.34021636843681335,
      "learning_rate": 3.8212842388863945e-05,
      "loss": 0.5123,
      "step": 52500
    },
    {
      "epoch": 23.798832510103278,
      "grad_norm": 0.31254976987838745,
      "learning_rate": 3.8100583744948366e-05,
      "loss": 0.5121,
      "step": 53000
    },
    {
      "epoch": 24.02334979793444,
      "grad_norm": 0.291567862033844,
      "learning_rate": 3.798832510103278e-05,
      "loss": 0.5121,
      "step": 53500
    },
    {
      "epoch": 24.247867085765606,
      "grad_norm": 0.28707391023635864,
      "learning_rate": 3.78760664571172e-05,
      "loss": 0.5117,
      "step": 54000
    },
    {
      "epoch": 24.472384373596768,
      "grad_norm": 0.30397069454193115,
      "learning_rate": 3.7763807813201616e-05,
      "loss": 0.5118,
      "step": 54500
    },
    {
      "epoch": 24.69690166142793,
      "grad_norm": 0.41119876503944397,
      "learning_rate": 3.765154916928604e-05,
      "loss": 0.512,
      "step": 55000
    },
    {
      "epoch": 24.921418949259092,
      "grad_norm": 0.3076551854610443,
      "learning_rate": 3.753929052537046e-05,
      "loss": 0.5122,
      "step": 55500
    },
    {
      "epoch": 25.145936237090257,
      "grad_norm": 0.29043591022491455,
      "learning_rate": 3.742703188145487e-05,
      "loss": 0.512,
      "step": 56000
    },
    {
      "epoch": 25.37045352492142,
      "grad_norm": 0.35290050506591797,
      "learning_rate": 3.7314773237539294e-05,
      "loss": 0.5118,
      "step": 56500
    },
    {
      "epoch": 25.59497081275258,
      "grad_norm": 0.3311685025691986,
      "learning_rate": 3.720251459362371e-05,
      "loss": 0.5116,
      "step": 57000
    },
    {
      "epoch": 25.819488100583744,
      "grad_norm": 0.2899410128593445,
      "learning_rate": 3.709025594970813e-05,
      "loss": 0.5117,
      "step": 57500
    },
    {
      "epoch": 26.04400538841491,
      "grad_norm": 0.31360700726509094,
      "learning_rate": 3.697799730579255e-05,
      "loss": 0.5117,
      "step": 58000
    },
    {
      "epoch": 26.26852267624607,
      "grad_norm": 0.28954827785491943,
      "learning_rate": 3.6865738661876965e-05,
      "loss": 0.5118,
      "step": 58500
    },
    {
      "epoch": 26.493039964077234,
      "grad_norm": 0.28354892134666443,
      "learning_rate": 3.6753480017961386e-05,
      "loss": 0.5118,
      "step": 59000
    },
    {
      "epoch": 26.717557251908396,
      "grad_norm": 0.2814151644706726,
      "learning_rate": 3.66412213740458e-05,
      "loss": 0.5116,
      "step": 59500
    },
    {
      "epoch": 26.94207453973956,
      "grad_norm": 0.2522728145122528,
      "learning_rate": 3.652896273013022e-05,
      "loss": 0.5113,
      "step": 60000
    },
    {
      "epoch": 27.166591827570723,
      "grad_norm": 0.3139851987361908,
      "learning_rate": 3.641670408621464e-05,
      "loss": 0.5115,
      "step": 60500
    },
    {
      "epoch": 27.391109115401886,
      "grad_norm": 0.2944397032260895,
      "learning_rate": 3.630444544229906e-05,
      "loss": 0.5113,
      "step": 61000
    },
    {
      "epoch": 27.615626403233048,
      "grad_norm": 0.31552112102508545,
      "learning_rate": 3.619218679838348e-05,
      "loss": 0.5113,
      "step": 61500
    },
    {
      "epoch": 27.840143691064213,
      "grad_norm": 0.36445093154907227,
      "learning_rate": 3.607992815446789e-05,
      "loss": 0.5115,
      "step": 62000
    },
    {
      "epoch": 28.064660978895375,
      "grad_norm": 0.3233700394630432,
      "learning_rate": 3.5967669510552314e-05,
      "loss": 0.5111,
      "step": 62500
    },
    {
      "epoch": 28.289178266726537,
      "grad_norm": 0.3823966681957245,
      "learning_rate": 3.5855410866636735e-05,
      "loss": 0.5111,
      "step": 63000
    },
    {
      "epoch": 28.5136955545577,
      "grad_norm": 0.2596687972545624,
      "learning_rate": 3.574315222272115e-05,
      "loss": 0.5112,
      "step": 63500
    },
    {
      "epoch": 28.738212842388865,
      "grad_norm": 0.24822865426540375,
      "learning_rate": 3.563089357880557e-05,
      "loss": 0.5114,
      "step": 64000
    },
    {
      "epoch": 28.962730130220027,
      "grad_norm": 0.24887636303901672,
      "learning_rate": 3.5518634934889985e-05,
      "loss": 0.5112,
      "step": 64500
    },
    {
      "epoch": 29.18724741805119,
      "grad_norm": 0.3937584459781647,
      "learning_rate": 3.5406376290974406e-05,
      "loss": 0.5108,
      "step": 65000
    },
    {
      "epoch": 29.41176470588235,
      "grad_norm": 0.26900890469551086,
      "learning_rate": 3.529411764705883e-05,
      "loss": 0.5112,
      "step": 65500
    },
    {
      "epoch": 29.636281993713517,
      "grad_norm": 0.2934080958366394,
      "learning_rate": 3.518185900314324e-05,
      "loss": 0.5113,
      "step": 66000
    },
    {
      "epoch": 29.86079928154468,
      "grad_norm": 0.30605778098106384,
      "learning_rate": 3.506960035922766e-05,
      "loss": 0.511,
      "step": 66500
    },
    {
      "epoch": 30.08531656937584,
      "grad_norm": 0.24887526035308838,
      "learning_rate": 3.4957341715312084e-05,
      "loss": 0.511,
      "step": 67000
    },
    {
      "epoch": 30.309833857207003,
      "grad_norm": 0.32399821281433105,
      "learning_rate": 3.48450830713965e-05,
      "loss": 0.5108,
      "step": 67500
    },
    {
      "epoch": 30.53435114503817,
      "grad_norm": 0.2870972454547882,
      "learning_rate": 3.473282442748092e-05,
      "loss": 0.5109,
      "step": 68000
    },
    {
      "epoch": 30.75886843286933,
      "grad_norm": 0.3034707009792328,
      "learning_rate": 3.4620565783565334e-05,
      "loss": 0.5108,
      "step": 68500
    },
    {
      "epoch": 30.983385720700493,
      "grad_norm": 0.29505375027656555,
      "learning_rate": 3.4508307139649755e-05,
      "loss": 0.5109,
      "step": 69000
    },
    {
      "epoch": 31.207903008531655,
      "grad_norm": 0.4101738929748535,
      "learning_rate": 3.4396048495734176e-05,
      "loss": 0.5109,
      "step": 69500
    },
    {
      "epoch": 31.43242029636282,
      "grad_norm": 0.2720175087451935,
      "learning_rate": 3.428378985181859e-05,
      "loss": 0.5105,
      "step": 70000
    },
    {
      "epoch": 31.656937584193983,
      "grad_norm": 0.3046509921550751,
      "learning_rate": 3.417153120790301e-05,
      "loss": 0.5108,
      "step": 70500
    },
    {
      "epoch": 31.881454872025145,
      "grad_norm": 0.3322061002254486,
      "learning_rate": 3.4059272563987426e-05,
      "loss": 0.5107,
      "step": 71000
    },
    {
      "epoch": 32.10597215985631,
      "grad_norm": 0.3240184783935547,
      "learning_rate": 3.394701392007185e-05,
      "loss": 0.5105,
      "step": 71500
    },
    {
      "epoch": 32.33048944768747,
      "grad_norm": 0.3532576560974121,
      "learning_rate": 3.383475527615627e-05,
      "loss": 0.5105,
      "step": 72000
    },
    {
      "epoch": 32.55500673551863,
      "grad_norm": 0.2872903645038605,
      "learning_rate": 3.372249663224068e-05,
      "loss": 0.5105,
      "step": 72500
    },
    {
      "epoch": 32.7795240233498,
      "grad_norm": 0.2860231101512909,
      "learning_rate": 3.3610237988325104e-05,
      "loss": 0.5107,
      "step": 73000
    },
    {
      "epoch": 33.00404131118096,
      "grad_norm": 0.29952123761177063,
      "learning_rate": 3.349797934440952e-05,
      "loss": 0.5106,
      "step": 73500
    },
    {
      "epoch": 33.228558599012125,
      "grad_norm": 0.32909026741981506,
      "learning_rate": 3.338572070049394e-05,
      "loss": 0.5103,
      "step": 74000
    },
    {
      "epoch": 33.45307588684329,
      "grad_norm": 0.27829718589782715,
      "learning_rate": 3.327346205657836e-05,
      "loss": 0.5104,
      "step": 74500
    },
    {
      "epoch": 33.67759317467445,
      "grad_norm": 0.29644304513931274,
      "learning_rate": 3.3161203412662775e-05,
      "loss": 0.5102,
      "step": 75000
    },
    {
      "epoch": 33.90211046250561,
      "grad_norm": 0.28949370980262756,
      "learning_rate": 3.3048944768747196e-05,
      "loss": 0.5105,
      "step": 75500
    },
    {
      "epoch": 34.12662775033677,
      "grad_norm": 0.23562981188297272,
      "learning_rate": 3.293668612483161e-05,
      "loss": 0.5107,
      "step": 76000
    },
    {
      "epoch": 34.35114503816794,
      "grad_norm": 0.3265102803707123,
      "learning_rate": 3.282442748091603e-05,
      "loss": 0.51,
      "step": 76500
    },
    {
      "epoch": 34.575662325999104,
      "grad_norm": 0.29270410537719727,
      "learning_rate": 3.271216883700045e-05,
      "loss": 0.5106,
      "step": 77000
    },
    {
      "epoch": 34.80017961383027,
      "grad_norm": 0.32749301195144653,
      "learning_rate": 3.2599910193084874e-05,
      "loss": 0.5103,
      "step": 77500
    },
    {
      "epoch": 35.02469690166143,
      "grad_norm": 0.3484084904193878,
      "learning_rate": 3.248765154916929e-05,
      "loss": 0.5103,
      "step": 78000
    },
    {
      "epoch": 35.24921418949259,
      "grad_norm": 0.25130540132522583,
      "learning_rate": 3.23753929052537e-05,
      "loss": 0.5103,
      "step": 78500
    },
    {
      "epoch": 35.47373147732375,
      "grad_norm": 0.28281012177467346,
      "learning_rate": 3.2263134261338124e-05,
      "loss": 0.5099,
      "step": 79000
    },
    {
      "epoch": 35.698248765154915,
      "grad_norm": 0.2804766297340393,
      "learning_rate": 3.2150875617422545e-05,
      "loss": 0.5101,
      "step": 79500
    },
    {
      "epoch": 35.92276605298608,
      "grad_norm": 0.25809812545776367,
      "learning_rate": 3.2038616973506966e-05,
      "loss": 0.5103,
      "step": 80000
    },
    {
      "epoch": 36.147283340817246,
      "grad_norm": 0.2423684149980545,
      "learning_rate": 3.192635832959138e-05,
      "loss": 0.5098,
      "step": 80500
    },
    {
      "epoch": 36.37180062864841,
      "grad_norm": 0.3269474506378174,
      "learning_rate": 3.1814099685675795e-05,
      "loss": 0.51,
      "step": 81000
    },
    {
      "epoch": 36.59631791647957,
      "grad_norm": 0.28104034066200256,
      "learning_rate": 3.1701841041760216e-05,
      "loss": 0.51,
      "step": 81500
    },
    {
      "epoch": 36.82083520431073,
      "grad_norm": 0.33384960889816284,
      "learning_rate": 3.158958239784464e-05,
      "loss": 0.5101,
      "step": 82000
    },
    {
      "epoch": 37.045352492141895,
      "grad_norm": 0.3585093319416046,
      "learning_rate": 3.147732375392906e-05,
      "loss": 0.5102,
      "step": 82500
    },
    {
      "epoch": 37.26986977997306,
      "grad_norm": 0.2836534082889557,
      "learning_rate": 3.136506511001347e-05,
      "loss": 0.5099,
      "step": 83000
    },
    {
      "epoch": 37.49438706780422,
      "grad_norm": 0.29705703258514404,
      "learning_rate": 3.125280646609789e-05,
      "loss": 0.5097,
      "step": 83500
    },
    {
      "epoch": 37.71890435563538,
      "grad_norm": 0.37838906049728394,
      "learning_rate": 3.114054782218231e-05,
      "loss": 0.5099,
      "step": 84000
    },
    {
      "epoch": 37.94342164346655,
      "grad_norm": 0.2997431755065918,
      "learning_rate": 3.102828917826673e-05,
      "loss": 0.5098,
      "step": 84500
    },
    {
      "epoch": 38.16793893129771,
      "grad_norm": 0.24270400404930115,
      "learning_rate": 3.091603053435115e-05,
      "loss": 0.51,
      "step": 85000
    },
    {
      "epoch": 38.392456219128874,
      "grad_norm": 0.3060562014579773,
      "learning_rate": 3.0803771890435565e-05,
      "loss": 0.5098,
      "step": 85500
    },
    {
      "epoch": 38.616973506960036,
      "grad_norm": 0.28744086623191833,
      "learning_rate": 3.069151324651998e-05,
      "loss": 0.5098,
      "step": 86000
    },
    {
      "epoch": 38.8414907947912,
      "grad_norm": 0.2685544490814209,
      "learning_rate": 3.05792546026044e-05,
      "loss": 0.5096,
      "step": 86500
    },
    {
      "epoch": 39.06600808262236,
      "grad_norm": 0.2736693322658539,
      "learning_rate": 3.046699595868882e-05,
      "loss": 0.5095,
      "step": 87000
    },
    {
      "epoch": 39.29052537045352,
      "grad_norm": 0.3225095868110657,
      "learning_rate": 3.035473731477324e-05,
      "loss": 0.5095,
      "step": 87500
    },
    {
      "epoch": 39.515042658284685,
      "grad_norm": 0.2646413743495941,
      "learning_rate": 3.024247867085766e-05,
      "loss": 0.5094,
      "step": 88000
    },
    {
      "epoch": 39.739559946115854,
      "grad_norm": 0.22884823381900787,
      "learning_rate": 3.0130220026942075e-05,
      "loss": 0.5098,
      "step": 88500
    },
    {
      "epoch": 39.964077233947016,
      "grad_norm": 0.38226088881492615,
      "learning_rate": 3.0017961383026492e-05,
      "loss": 0.5097,
      "step": 89000
    },
    {
      "epoch": 40.18859452177818,
      "grad_norm": 0.27229243516921997,
      "learning_rate": 2.9905702739110914e-05,
      "loss": 0.5095,
      "step": 89500
    },
    {
      "epoch": 40.41311180960934,
      "grad_norm": 0.3130737841129303,
      "learning_rate": 2.9793444095195335e-05,
      "loss": 0.5094,
      "step": 90000
    },
    {
      "epoch": 40.6376290974405,
      "grad_norm": 0.26448535919189453,
      "learning_rate": 2.9681185451279752e-05,
      "loss": 0.5096,
      "step": 90500
    },
    {
      "epoch": 40.862146385271664,
      "grad_norm": 0.24292819201946259,
      "learning_rate": 2.9568926807364167e-05,
      "loss": 0.5095,
      "step": 91000
    },
    {
      "epoch": 41.08666367310283,
      "grad_norm": 0.25939568877220154,
      "learning_rate": 2.9456668163448588e-05,
      "loss": 0.5095,
      "step": 91500
    },
    {
      "epoch": 41.31118096093399,
      "grad_norm": 0.2717379927635193,
      "learning_rate": 2.9344409519533006e-05,
      "loss": 0.5094,
      "step": 92000
    },
    {
      "epoch": 41.53569824876516,
      "grad_norm": 0.2534502446651459,
      "learning_rate": 2.9232150875617427e-05,
      "loss": 0.5091,
      "step": 92500
    },
    {
      "epoch": 41.76021553659632,
      "grad_norm": 0.25486767292022705,
      "learning_rate": 2.911989223170184e-05,
      "loss": 0.5094,
      "step": 93000
    },
    {
      "epoch": 41.98473282442748,
      "grad_norm": 0.3049001395702362,
      "learning_rate": 2.900763358778626e-05,
      "loss": 0.5094,
      "step": 93500
    },
    {
      "epoch": 42.209250112258644,
      "grad_norm": 0.22568590939044952,
      "learning_rate": 2.889537494387068e-05,
      "loss": 0.5091,
      "step": 94000
    },
    {
      "epoch": 42.433767400089806,
      "grad_norm": 0.2827911376953125,
      "learning_rate": 2.8783116299955098e-05,
      "loss": 0.5093,
      "step": 94500
    },
    {
      "epoch": 42.65828468792097,
      "grad_norm": 0.24048054218292236,
      "learning_rate": 2.867085765603952e-05,
      "loss": 0.5094,
      "step": 95000
    },
    {
      "epoch": 42.88280197575213,
      "grad_norm": 0.269528329372406,
      "learning_rate": 2.8558599012123933e-05,
      "loss": 0.5091,
      "step": 95500
    },
    {
      "epoch": 43.10731926358329,
      "grad_norm": 0.3095631003379822,
      "learning_rate": 2.844634036820835e-05,
      "loss": 0.5092,
      "step": 96000
    },
    {
      "epoch": 43.33183655141446,
      "grad_norm": 0.30425190925598145,
      "learning_rate": 2.8334081724292772e-05,
      "loss": 0.509,
      "step": 96500
    },
    {
      "epoch": 43.556353839245624,
      "grad_norm": 0.32014742493629456,
      "learning_rate": 2.822182308037719e-05,
      "loss": 0.5093,
      "step": 97000
    },
    {
      "epoch": 43.780871127076786,
      "grad_norm": 0.36089012026786804,
      "learning_rate": 2.810956443646161e-05,
      "loss": 0.5092,
      "step": 97500
    },
    {
      "epoch": 44.00538841490795,
      "grad_norm": 0.2780629098415375,
      "learning_rate": 2.7997305792546026e-05,
      "loss": 0.5091,
      "step": 98000
    },
    {
      "epoch": 44.22990570273911,
      "grad_norm": 0.23857545852661133,
      "learning_rate": 2.7885047148630443e-05,
      "loss": 0.5089,
      "step": 98500
    },
    {
      "epoch": 44.45442299057027,
      "grad_norm": 0.31357964873313904,
      "learning_rate": 2.7772788504714865e-05,
      "loss": 0.5091,
      "step": 99000
    },
    {
      "epoch": 44.678940278401434,
      "grad_norm": 0.23284994065761566,
      "learning_rate": 2.7660529860799282e-05,
      "loss": 0.509,
      "step": 99500
    },
    {
      "epoch": 44.9034575662326,
      "grad_norm": 0.2653292119503021,
      "learning_rate": 2.7548271216883703e-05,
      "loss": 0.5092,
      "step": 100000
    },
    {
      "epoch": 45.127974854063766,
      "grad_norm": 0.303409218788147,
      "learning_rate": 2.7436012572968118e-05,
      "loss": 0.5089,
      "step": 100500
    },
    {
      "epoch": 45.35249214189493,
      "grad_norm": 0.2692939341068268,
      "learning_rate": 2.7323753929052536e-05,
      "loss": 0.509,
      "step": 101000
    },
    {
      "epoch": 45.57700942972609,
      "grad_norm": 0.2352137416601181,
      "learning_rate": 2.7211495285136957e-05,
      "loss": 0.509,
      "step": 101500
    },
    {
      "epoch": 45.80152671755725,
      "grad_norm": 0.2490929663181305,
      "learning_rate": 2.7099236641221375e-05,
      "loss": 0.5086,
      "step": 102000
    },
    {
      "epoch": 46.026044005388414,
      "grad_norm": 0.2861158549785614,
      "learning_rate": 2.6986977997305796e-05,
      "loss": 0.509,
      "step": 102500
    },
    {
      "epoch": 46.250561293219576,
      "grad_norm": 0.296600878238678,
      "learning_rate": 2.687471935339021e-05,
      "loss": 0.5087,
      "step": 103000
    },
    {
      "epoch": 46.47507858105074,
      "grad_norm": 0.27728283405303955,
      "learning_rate": 2.6762460709474628e-05,
      "loss": 0.5087,
      "step": 103500
    },
    {
      "epoch": 46.69959586888191,
      "grad_norm": 0.2457495480775833,
      "learning_rate": 2.665020206555905e-05,
      "loss": 0.5088,
      "step": 104000
    },
    {
      "epoch": 46.92411315671307,
      "grad_norm": 0.24751338362693787,
      "learning_rate": 2.653794342164347e-05,
      "loss": 0.5089,
      "step": 104500
    },
    {
      "epoch": 47.14863044454423,
      "grad_norm": 0.2669333815574646,
      "learning_rate": 2.6425684777727888e-05,
      "loss": 0.5084,
      "step": 105000
    },
    {
      "epoch": 47.373147732375394,
      "grad_norm": 0.21805399656295776,
      "learning_rate": 2.6313426133812302e-05,
      "loss": 0.5086,
      "step": 105500
    },
    {
      "epoch": 47.597665020206556,
      "grad_norm": 0.25298914313316345,
      "learning_rate": 2.6201167489896723e-05,
      "loss": 0.509,
      "step": 106000
    },
    {
      "epoch": 47.82218230803772,
      "grad_norm": 0.2851361930370331,
      "learning_rate": 2.608890884598114e-05,
      "loss": 0.5085,
      "step": 106500
    },
    {
      "epoch": 48.04669959586888,
      "grad_norm": 0.2997959554195404,
      "learning_rate": 2.5976650202065562e-05,
      "loss": 0.5086,
      "step": 107000
    },
    {
      "epoch": 48.27121688370004,
      "grad_norm": 0.21631930768489838,
      "learning_rate": 2.586439155814998e-05,
      "loss": 0.5084,
      "step": 107500
    },
    {
      "epoch": 48.49573417153121,
      "grad_norm": 0.2502560615539551,
      "learning_rate": 2.5752132914234394e-05,
      "loss": 0.5087,
      "step": 108000
    },
    {
      "epoch": 48.72025145936237,
      "grad_norm": 0.20570141077041626,
      "learning_rate": 2.5639874270318816e-05,
      "loss": 0.5084,
      "step": 108500
    },
    {
      "epoch": 48.944768747193535,
      "grad_norm": 0.2705649435520172,
      "learning_rate": 2.5527615626403233e-05,
      "loss": 0.5088,
      "step": 109000
    },
    {
      "epoch": 49.1692860350247,
      "grad_norm": 0.27055010199546814,
      "learning_rate": 2.5415356982487654e-05,
      "loss": 0.5087,
      "step": 109500
    },
    {
      "epoch": 49.39380332285586,
      "grad_norm": 0.23606812953948975,
      "learning_rate": 2.5303098338572072e-05,
      "loss": 0.5085,
      "step": 110000
    },
    {
      "epoch": 49.61832061068702,
      "grad_norm": 0.27449411153793335,
      "learning_rate": 2.5190839694656487e-05,
      "loss": 0.5083,
      "step": 110500
    },
    {
      "epoch": 49.842837898518184,
      "grad_norm": 0.2987942695617676,
      "learning_rate": 2.5078581050740908e-05,
      "loss": 0.5084,
      "step": 111000
    },
    {
      "epoch": 50.067355186349346,
      "grad_norm": 0.2656092941761017,
      "learning_rate": 2.4966322406825326e-05,
      "loss": 0.5085,
      "step": 111500
    },
    {
      "epoch": 50.291872474180515,
      "grad_norm": 0.3434534966945648,
      "learning_rate": 2.4854063762909747e-05,
      "loss": 0.5082,
      "step": 112000
    },
    {
      "epoch": 50.51638976201168,
      "grad_norm": 0.2522437572479248,
      "learning_rate": 2.4741805118994164e-05,
      "loss": 0.5084,
      "step": 112500
    },
    {
      "epoch": 50.74090704984284,
      "grad_norm": 0.2569507956504822,
      "learning_rate": 2.4629546475078582e-05,
      "loss": 0.5083,
      "step": 113000
    },
    {
      "epoch": 50.965424337674,
      "grad_norm": 0.2421199530363083,
      "learning_rate": 2.4517287831163e-05,
      "loss": 0.5083,
      "step": 113500
    },
    {
      "epoch": 51.18994162550516,
      "grad_norm": 0.29556506872177124,
      "learning_rate": 2.4405029187247418e-05,
      "loss": 0.5081,
      "step": 114000
    },
    {
      "epoch": 51.414458913336325,
      "grad_norm": 0.26273369789123535,
      "learning_rate": 2.429277054333184e-05,
      "loss": 0.5083,
      "step": 114500
    },
    {
      "epoch": 51.63897620116749,
      "grad_norm": 0.2612042725086212,
      "learning_rate": 2.4180511899416257e-05,
      "loss": 0.5083,
      "step": 115000
    },
    {
      "epoch": 51.86349348899865,
      "grad_norm": 0.33283501863479614,
      "learning_rate": 2.4068253255500674e-05,
      "loss": 0.5082,
      "step": 115500
    },
    {
      "epoch": 52.08801077682982,
      "grad_norm": 0.23167358338832855,
      "learning_rate": 2.3955994611585092e-05,
      "loss": 0.5081,
      "step": 116000
    },
    {
      "epoch": 52.31252806466098,
      "grad_norm": 0.2755446135997772,
      "learning_rate": 2.384373596766951e-05,
      "loss": 0.5081,
      "step": 116500
    },
    {
      "epoch": 52.53704535249214,
      "grad_norm": 0.25303366780281067,
      "learning_rate": 2.373147732375393e-05,
      "loss": 0.5081,
      "step": 117000
    },
    {
      "epoch": 52.761562640323305,
      "grad_norm": 0.24417133629322052,
      "learning_rate": 2.361921867983835e-05,
      "loss": 0.5082,
      "step": 117500
    },
    {
      "epoch": 52.98607992815447,
      "grad_norm": 0.2147074192762375,
      "learning_rate": 2.3506960035922767e-05,
      "loss": 0.5082,
      "step": 118000
    },
    {
      "epoch": 53.21059721598563,
      "grad_norm": 0.22925825417041779,
      "learning_rate": 2.3394701392007184e-05,
      "loss": 0.5078,
      "step": 118500
    },
    {
      "epoch": 53.43511450381679,
      "grad_norm": 0.3772825598716736,
      "learning_rate": 2.3282442748091605e-05,
      "loss": 0.5079,
      "step": 119000
    },
    {
      "epoch": 53.65963179164795,
      "grad_norm": 0.23974214494228363,
      "learning_rate": 2.3170184104176023e-05,
      "loss": 0.5083,
      "step": 119500
    },
    {
      "epoch": 53.88414907947912,
      "grad_norm": 0.2585788667201996,
      "learning_rate": 2.305792546026044e-05,
      "loss": 0.5081,
      "step": 120000
    },
    {
      "epoch": 54.108666367310285,
      "grad_norm": 0.2728787064552307,
      "learning_rate": 2.294566681634486e-05,
      "loss": 0.508,
      "step": 120500
    },
    {
      "epoch": 54.33318365514145,
      "grad_norm": 0.29325369000434875,
      "learning_rate": 2.2833408172429277e-05,
      "loss": 0.5078,
      "step": 121000
    },
    {
      "epoch": 54.55770094297261,
      "grad_norm": 0.25119897723197937,
      "learning_rate": 2.2721149528513698e-05,
      "loss": 0.5079,
      "step": 121500
    },
    {
      "epoch": 54.78221823080377,
      "grad_norm": 0.31835100054740906,
      "learning_rate": 2.2608890884598115e-05,
      "loss": 0.5079,
      "step": 122000
    },
    {
      "epoch": 55.00673551863493,
      "grad_norm": 0.2949099838733673,
      "learning_rate": 2.2496632240682533e-05,
      "loss": 0.508,
      "step": 122500
    },
    {
      "epoch": 55.231252806466095,
      "grad_norm": 0.297603577375412,
      "learning_rate": 2.2384373596766954e-05,
      "loss": 0.5076,
      "step": 123000
    },
    {
      "epoch": 55.455770094297264,
      "grad_norm": 0.24909868836402893,
      "learning_rate": 2.227211495285137e-05,
      "loss": 0.5079,
      "step": 123500
    },
    {
      "epoch": 55.68028738212843,
      "grad_norm": 0.29941731691360474,
      "learning_rate": 2.215985630893579e-05,
      "loss": 0.5078,
      "step": 124000
    },
    {
      "epoch": 55.90480466995959,
      "grad_norm": 0.2502264678478241,
      "learning_rate": 2.2047597665020208e-05,
      "loss": 0.5081,
      "step": 124500
    },
    {
      "epoch": 56.12932195779075,
      "grad_norm": 0.26961758732795715,
      "learning_rate": 2.1935339021104625e-05,
      "loss": 0.5077,
      "step": 125000
    },
    {
      "epoch": 56.35383924562191,
      "grad_norm": 0.28054115176200867,
      "learning_rate": 2.1823080377189047e-05,
      "loss": 0.5079,
      "step": 125500
    },
    {
      "epoch": 56.578356533453075,
      "grad_norm": 0.2793070673942566,
      "learning_rate": 2.171082173327346e-05,
      "loss": 0.5074,
      "step": 126000
    },
    {
      "epoch": 56.80287382128424,
      "grad_norm": 0.34063732624053955,
      "learning_rate": 2.1598563089357882e-05,
      "loss": 0.5079,
      "step": 126500
    },
    {
      "epoch": 57.0273911091154,
      "grad_norm": 0.28606662154197693,
      "learning_rate": 2.14863044454423e-05,
      "loss": 0.5079,
      "step": 127000
    },
    {
      "epoch": 57.25190839694657,
      "grad_norm": 0.2761017084121704,
      "learning_rate": 2.1374045801526718e-05,
      "loss": 0.5078,
      "step": 127500
    },
    {
      "epoch": 57.47642568477773,
      "grad_norm": 0.29059192538261414,
      "learning_rate": 2.126178715761114e-05,
      "loss": 0.5078,
      "step": 128000
    },
    {
      "epoch": 57.70094297260889,
      "grad_norm": 0.26145732402801514,
      "learning_rate": 2.1149528513695553e-05,
      "loss": 0.5076,
      "step": 128500
    },
    {
      "epoch": 57.925460260440055,
      "grad_norm": 0.30884578824043274,
      "learning_rate": 2.1037269869779974e-05,
      "loss": 0.5075,
      "step": 129000
    },
    {
      "epoch": 58.14997754827122,
      "grad_norm": 0.2141338735818863,
      "learning_rate": 2.0925011225864395e-05,
      "loss": 0.5077,
      "step": 129500
    },
    {
      "epoch": 58.37449483610238,
      "grad_norm": 0.2784568667411804,
      "learning_rate": 2.081275258194881e-05,
      "loss": 0.5076,
      "step": 130000
    },
    {
      "epoch": 58.59901212393354,
      "grad_norm": 0.2704363167285919,
      "learning_rate": 2.070049393803323e-05,
      "loss": 0.5075,
      "step": 130500
    },
    {
      "epoch": 58.8235294117647,
      "grad_norm": 0.24420513212680817,
      "learning_rate": 2.058823529411765e-05,
      "loss": 0.5078,
      "step": 131000
    },
    {
      "epoch": 59.04804669959587,
      "grad_norm": 0.28773993253707886,
      "learning_rate": 2.0475976650202066e-05,
      "loss": 0.5076,
      "step": 131500
    },
    {
      "epoch": 59.272563987427034,
      "grad_norm": 0.30819907784461975,
      "learning_rate": 2.0363718006286488e-05,
      "loss": 0.5075,
      "step": 132000
    },
    {
      "epoch": 59.497081275258196,
      "grad_norm": 0.2233600616455078,
      "learning_rate": 2.0251459362370902e-05,
      "loss": 0.5076,
      "step": 132500
    },
    {
      "epoch": 59.72159856308936,
      "grad_norm": 0.25416216254234314,
      "learning_rate": 2.0139200718455323e-05,
      "loss": 0.5075,
      "step": 133000
    },
    {
      "epoch": 59.94611585092052,
      "grad_norm": 0.32486632466316223,
      "learning_rate": 2.002694207453974e-05,
      "loss": 0.5075,
      "step": 133500
    },
    {
      "epoch": 60.17063313875168,
      "grad_norm": 0.2555195391178131,
      "learning_rate": 1.991468343062416e-05,
      "loss": 0.5073,
      "step": 134000
    },
    {
      "epoch": 60.395150426582845,
      "grad_norm": 0.2999102473258972,
      "learning_rate": 1.980242478670858e-05,
      "loss": 0.5073,
      "step": 134500
    },
    {
      "epoch": 60.61966771441401,
      "grad_norm": 0.26124438643455505,
      "learning_rate": 1.9690166142792994e-05,
      "loss": 0.5076,
      "step": 135000
    },
    {
      "epoch": 60.844185002245176,
      "grad_norm": 0.241445392370224,
      "learning_rate": 1.9577907498877415e-05,
      "loss": 0.5072,
      "step": 135500
    },
    {
      "epoch": 61.06870229007634,
      "grad_norm": 0.29960766434669495,
      "learning_rate": 1.9465648854961833e-05,
      "loss": 0.5074,
      "step": 136000
    },
    {
      "epoch": 61.2932195779075,
      "grad_norm": 0.26445236802101135,
      "learning_rate": 1.935339021104625e-05,
      "loss": 0.5071,
      "step": 136500
    },
    {
      "epoch": 61.51773686573866,
      "grad_norm": 0.2566162943840027,
      "learning_rate": 1.9241131567130672e-05,
      "loss": 0.5071,
      "step": 137000
    },
    {
      "epoch": 61.742254153569824,
      "grad_norm": 0.2961127758026123,
      "learning_rate": 1.912887292321509e-05,
      "loss": 0.5075,
      "step": 137500
    },
    {
      "epoch": 61.96677144140099,
      "grad_norm": 0.25584056973457336,
      "learning_rate": 1.9016614279299507e-05,
      "loss": 0.5076,
      "step": 138000
    },
    {
      "epoch": 62.19128872923215,
      "grad_norm": 0.24351227283477783,
      "learning_rate": 1.8904355635383925e-05,
      "loss": 0.507,
      "step": 138500
    },
    {
      "epoch": 62.41580601706331,
      "grad_norm": 0.28104233741760254,
      "learning_rate": 1.8792096991468343e-05,
      "loss": 0.5071,
      "step": 139000
    },
    {
      "epoch": 62.64032330489448,
      "grad_norm": 0.22899611294269562,
      "learning_rate": 1.867983834755276e-05,
      "loss": 0.5074,
      "step": 139500
    },
    {
      "epoch": 62.86484059272564,
      "grad_norm": 0.2771306335926056,
      "learning_rate": 1.8567579703637182e-05,
      "loss": 0.5073,
      "step": 140000
    },
    {
      "epoch": 63.089357880556804,
      "grad_norm": 0.25976455211639404,
      "learning_rate": 1.84553210597216e-05,
      "loss": 0.5071,
      "step": 140500
    },
    {
      "epoch": 63.313875168387966,
      "grad_norm": 0.26789993047714233,
      "learning_rate": 1.8343062415806017e-05,
      "loss": 0.5069,
      "step": 141000
    },
    {
      "epoch": 63.53839245621913,
      "grad_norm": 0.2597350478172302,
      "learning_rate": 1.8230803771890435e-05,
      "loss": 0.5072,
      "step": 141500
    },
    {
      "epoch": 63.76290974405029,
      "grad_norm": 0.27043604850769043,
      "learning_rate": 1.8118545127974853e-05,
      "loss": 0.5074,
      "step": 142000
    },
    {
      "epoch": 63.98742703188145,
      "grad_norm": 0.263091117143631,
      "learning_rate": 1.8006286484059274e-05,
      "loss": 0.5071,
      "step": 142500
    },
    {
      "epoch": 64.21194431971261,
      "grad_norm": 0.25214675068855286,
      "learning_rate": 1.7894027840143692e-05,
      "loss": 0.5068,
      "step": 143000
    },
    {
      "epoch": 64.43646160754378,
      "grad_norm": 0.3068860173225403,
      "learning_rate": 1.778176919622811e-05,
      "loss": 0.507,
      "step": 143500
    },
    {
      "epoch": 64.66097889537494,
      "grad_norm": 0.2665645480155945,
      "learning_rate": 1.766951055231253e-05,
      "loss": 0.5069,
      "step": 144000
    },
    {
      "epoch": 64.8854961832061,
      "grad_norm": 0.28451040387153625,
      "learning_rate": 1.7557251908396945e-05,
      "loss": 0.5071,
      "step": 144500
    },
    {
      "epoch": 65.11001347103726,
      "grad_norm": 0.27097034454345703,
      "learning_rate": 1.7444993264481366e-05,
      "loss": 0.5073,
      "step": 145000
    },
    {
      "epoch": 65.33453075886844,
      "grad_norm": 0.24408435821533203,
      "learning_rate": 1.7332734620565784e-05,
      "loss": 0.5069,
      "step": 145500
    },
    {
      "epoch": 65.5590480466996,
      "grad_norm": 0.29556044936180115,
      "learning_rate": 1.7220475976650202e-05,
      "loss": 0.5069,
      "step": 146000
    },
    {
      "epoch": 65.78356533453076,
      "grad_norm": 0.22931714355945587,
      "learning_rate": 1.7108217332734623e-05,
      "loss": 0.5072,
      "step": 146500
    },
    {
      "epoch": 66.00808262236193,
      "grad_norm": 0.25115445256233215,
      "learning_rate": 1.6995958688819037e-05,
      "loss": 0.5068,
      "step": 147000
    },
    {
      "epoch": 66.23259991019309,
      "grad_norm": 0.29000961780548096,
      "learning_rate": 1.688370004490346e-05,
      "loss": 0.5067,
      "step": 147500
    },
    {
      "epoch": 66.45711719802425,
      "grad_norm": 0.28370824456214905,
      "learning_rate": 1.6771441400987876e-05,
      "loss": 0.507,
      "step": 148000
    },
    {
      "epoch": 66.68163448585541,
      "grad_norm": 0.29559633135795593,
      "learning_rate": 1.6659182757072294e-05,
      "loss": 0.507,
      "step": 148500
    },
    {
      "epoch": 66.90615177368657,
      "grad_norm": 0.2727641761302948,
      "learning_rate": 1.6546924113156715e-05,
      "loss": 0.5068,
      "step": 149000
    },
    {
      "epoch": 67.13066906151774,
      "grad_norm": 0.24431151151657104,
      "learning_rate": 1.643466546924113e-05,
      "loss": 0.5068,
      "step": 149500
    },
    {
      "epoch": 67.3551863493489,
      "grad_norm": 0.31061673164367676,
      "learning_rate": 1.632240682532555e-05,
      "loss": 0.5066,
      "step": 150000
    },
    {
      "epoch": 67.57970363718006,
      "grad_norm": 0.2662689685821533,
      "learning_rate": 1.6210148181409972e-05,
      "loss": 0.5069,
      "step": 150500
    },
    {
      "epoch": 67.80422092501122,
      "grad_norm": 0.2667848467826843,
      "learning_rate": 1.6097889537494386e-05,
      "loss": 0.5067,
      "step": 151000
    },
    {
      "epoch": 68.02873821284238,
      "grad_norm": 0.24847663938999176,
      "learning_rate": 1.5985630893578807e-05,
      "loss": 0.5069,
      "step": 151500
    },
    {
      "epoch": 68.25325550067355,
      "grad_norm": 0.2624165713787079,
      "learning_rate": 1.5873372249663225e-05,
      "loss": 0.5067,
      "step": 152000
    },
    {
      "epoch": 68.47777278850471,
      "grad_norm": 0.26347339153289795,
      "learning_rate": 1.5761113605747643e-05,
      "loss": 0.5067,
      "step": 152500
    },
    {
      "epoch": 68.70229007633588,
      "grad_norm": 0.26210281252861023,
      "learning_rate": 1.5648854961832064e-05,
      "loss": 0.5068,
      "step": 153000
    },
    {
      "epoch": 68.92680736416705,
      "grad_norm": 0.26727333664894104,
      "learning_rate": 1.553659631791648e-05,
      "loss": 0.5067,
      "step": 153500
    },
    {
      "epoch": 69.15132465199821,
      "grad_norm": 0.2684708833694458,
      "learning_rate": 1.54243376740009e-05,
      "loss": 0.5066,
      "step": 154000
    },
    {
      "epoch": 69.37584193982937,
      "grad_norm": 0.3159206509590149,
      "learning_rate": 1.5312079030085317e-05,
      "loss": 0.5067,
      "step": 154500
    },
    {
      "epoch": 69.60035922766053,
      "grad_norm": 0.2554440498352051,
      "learning_rate": 1.5199820386169735e-05,
      "loss": 0.5067,
      "step": 155000
    },
    {
      "epoch": 69.8248765154917,
      "grad_norm": 0.28516685962677,
      "learning_rate": 1.5087561742254156e-05,
      "loss": 0.5066,
      "step": 155500
    },
    {
      "epoch": 70.04939380332286,
      "grad_norm": 0.3011644184589386,
      "learning_rate": 1.4975303098338572e-05,
      "loss": 0.5067,
      "step": 156000
    },
    {
      "epoch": 70.27391109115402,
      "grad_norm": 0.3424302041530609,
      "learning_rate": 1.4863044454422992e-05,
      "loss": 0.5065,
      "step": 156500
    },
    {
      "epoch": 70.49842837898518,
      "grad_norm": 0.3285778760910034,
      "learning_rate": 1.475078581050741e-05,
      "loss": 0.5067,
      "step": 157000
    },
    {
      "epoch": 70.72294566681634,
      "grad_norm": 0.30656373500823975,
      "learning_rate": 1.4638527166591829e-05,
      "loss": 0.5065,
      "step": 157500
    },
    {
      "epoch": 70.9474629546475,
      "grad_norm": 0.2914215922355652,
      "learning_rate": 1.4526268522676248e-05,
      "loss": 0.5067,
      "step": 158000
    },
    {
      "epoch": 71.17198024247867,
      "grad_norm": 0.2871495485305786,
      "learning_rate": 1.4414009878760664e-05,
      "loss": 0.5064,
      "step": 158500
    },
    {
      "epoch": 71.39649753030983,
      "grad_norm": 0.21416766941547394,
      "learning_rate": 1.4301751234845084e-05,
      "loss": 0.5064,
      "step": 159000
    },
    {
      "epoch": 71.62101481814099,
      "grad_norm": 0.28914254903793335,
      "learning_rate": 1.4189492590929502e-05,
      "loss": 0.5066,
      "step": 159500
    },
    {
      "epoch": 71.84553210597215,
      "grad_norm": 0.20892077684402466,
      "learning_rate": 1.4077233947013921e-05,
      "loss": 0.5068,
      "step": 160000
    },
    {
      "epoch": 72.07004939380332,
      "grad_norm": 0.2385236769914627,
      "learning_rate": 1.396497530309834e-05,
      "loss": 0.5066,
      "step": 160500
    },
    {
      "epoch": 72.29456668163449,
      "grad_norm": 0.24884046614170074,
      "learning_rate": 1.3852716659182757e-05,
      "loss": 0.5064,
      "step": 161000
    },
    {
      "epoch": 72.51908396946565,
      "grad_norm": 0.2780567407608032,
      "learning_rate": 1.3740458015267178e-05,
      "loss": 0.5065,
      "step": 161500
    },
    {
      "epoch": 72.74360125729682,
      "grad_norm": 0.3086734712123871,
      "learning_rate": 1.3628199371351594e-05,
      "loss": 0.5063,
      "step": 162000
    },
    {
      "epoch": 72.96811854512798,
      "grad_norm": 0.2692095637321472,
      "learning_rate": 1.3515940727436013e-05,
      "loss": 0.5065,
      "step": 162500
    },
    {
      "epoch": 73.19263583295914,
      "grad_norm": 0.28371891379356384,
      "learning_rate": 1.3403682083520433e-05,
      "loss": 0.5063,
      "step": 163000
    },
    {
      "epoch": 73.4171531207903,
      "grad_norm": 0.24323005974292755,
      "learning_rate": 1.329142343960485e-05,
      "loss": 0.5063,
      "step": 163500
    },
    {
      "epoch": 73.64167040862147,
      "grad_norm": 0.28789713978767395,
      "learning_rate": 1.317916479568927e-05,
      "loss": 0.5064,
      "step": 164000
    },
    {
      "epoch": 73.86618769645263,
      "grad_norm": 0.22307805716991425,
      "learning_rate": 1.3066906151773686e-05,
      "loss": 0.5064,
      "step": 164500
    },
    {
      "epoch": 74.09070498428379,
      "grad_norm": 0.3385976254940033,
      "learning_rate": 1.2954647507858105e-05,
      "loss": 0.5064,
      "step": 165000
    },
    {
      "epoch": 74.31522227211495,
      "grad_norm": 0.25179600715637207,
      "learning_rate": 1.2842388863942525e-05,
      "loss": 0.5062,
      "step": 165500
    },
    {
      "epoch": 74.53973955994611,
      "grad_norm": 0.30082905292510986,
      "learning_rate": 1.2730130220026943e-05,
      "loss": 0.5064,
      "step": 166000
    },
    {
      "epoch": 74.76425684777728,
      "grad_norm": 0.24988405406475067,
      "learning_rate": 1.2617871576111362e-05,
      "loss": 0.5064,
      "step": 166500
    },
    {
      "epoch": 74.98877413560844,
      "grad_norm": 0.2599991261959076,
      "learning_rate": 1.2505612932195778e-05,
      "loss": 0.5062,
      "step": 167000
    },
    {
      "epoch": 75.2132914234396,
      "grad_norm": 0.24063149094581604,
      "learning_rate": 1.2393354288280198e-05,
      "loss": 0.506,
      "step": 167500
    },
    {
      "epoch": 75.43780871127076,
      "grad_norm": 0.2825841009616852,
      "learning_rate": 1.2281095644364617e-05,
      "loss": 0.5064,
      "step": 168000
    },
    {
      "epoch": 75.66232599910192,
      "grad_norm": 0.22714093327522278,
      "learning_rate": 1.2168837000449035e-05,
      "loss": 0.5062,
      "step": 168500
    },
    {
      "epoch": 75.8868432869331,
      "grad_norm": 0.2544926404953003,
      "learning_rate": 1.2056578356533453e-05,
      "loss": 0.5062,
      "step": 169000
    },
    {
      "epoch": 76.11136057476426,
      "grad_norm": 0.27082112431526184,
      "learning_rate": 1.1944319712617872e-05,
      "loss": 0.5062,
      "step": 169500
    },
    {
      "epoch": 76.33587786259542,
      "grad_norm": 0.27503469586372375,
      "learning_rate": 1.1832061068702292e-05,
      "loss": 0.5061,
      "step": 170000
    },
    {
      "epoch": 76.56039515042659,
      "grad_norm": 0.27403393387794495,
      "learning_rate": 1.171980242478671e-05,
      "loss": 0.5062,
      "step": 170500
    },
    {
      "epoch": 76.78491243825775,
      "grad_norm": 0.2857399880886078,
      "learning_rate": 1.1607543780871127e-05,
      "loss": 0.5061,
      "step": 171000
    },
    {
      "epoch": 77.00942972608891,
      "grad_norm": 0.3000244200229645,
      "learning_rate": 1.1495285136955545e-05,
      "loss": 0.5062,
      "step": 171500
    },
    {
      "epoch": 77.23394701392007,
      "grad_norm": 0.263568639755249,
      "learning_rate": 1.1383026493039966e-05,
      "loss": 0.5059,
      "step": 172000
    },
    {
      "epoch": 77.45846430175123,
      "grad_norm": 0.28810855746269226,
      "learning_rate": 1.1270767849124384e-05,
      "loss": 0.5059,
      "step": 172500
    },
    {
      "epoch": 77.6829815895824,
      "grad_norm": 0.25058862566947937,
      "learning_rate": 1.1158509205208801e-05,
      "loss": 0.5062,
      "step": 173000
    },
    {
      "epoch": 77.90749887741356,
      "grad_norm": 0.27970173954963684,
      "learning_rate": 1.104625056129322e-05,
      "loss": 0.506,
      "step": 173500
    },
    {
      "epoch": 78.13201616524472,
      "grad_norm": 0.27892768383026123,
      "learning_rate": 1.0933991917377639e-05,
      "loss": 0.5059,
      "step": 174000
    },
    {
      "epoch": 78.35653345307588,
      "grad_norm": 0.2946242392063141,
      "learning_rate": 1.0821733273462058e-05,
      "loss": 0.5061,
      "step": 174500
    },
    {
      "epoch": 78.58105074090705,
      "grad_norm": 0.28078168630599976,
      "learning_rate": 1.0709474629546476e-05,
      "loss": 0.5061,
      "step": 175000
    },
    {
      "epoch": 78.80556802873821,
      "grad_norm": 0.26599106192588806,
      "learning_rate": 1.0597215985630894e-05,
      "loss": 0.5062,
      "step": 175500
    },
    {
      "epoch": 79.03008531656937,
      "grad_norm": 0.3320469558238983,
      "learning_rate": 1.0484957341715313e-05,
      "loss": 0.506,
      "step": 176000
    },
    {
      "epoch": 79.25460260440055,
      "grad_norm": 0.2670513689517975,
      "learning_rate": 1.0372698697799731e-05,
      "loss": 0.5059,
      "step": 176500
    },
    {
      "epoch": 79.47911989223171,
      "grad_norm": 0.2321455478668213,
      "learning_rate": 1.026044005388415e-05,
      "loss": 0.5059,
      "step": 177000
    },
    {
      "epoch": 79.70363718006287,
      "grad_norm": 0.2755843698978424,
      "learning_rate": 1.0148181409968568e-05,
      "loss": 0.506,
      "step": 177500
    },
    {
      "epoch": 79.92815446789403,
      "grad_norm": 0.2875913977622986,
      "learning_rate": 1.0035922766052988e-05,
      "loss": 0.506,
      "step": 178000
    },
    {
      "epoch": 80.1526717557252,
      "grad_norm": 0.34286192059516907,
      "learning_rate": 9.923664122137405e-06,
      "loss": 0.5056,
      "step": 178500
    },
    {
      "epoch": 80.37718904355636,
      "grad_norm": 0.2643374502658844,
      "learning_rate": 9.811405478221823e-06,
      "loss": 0.506,
      "step": 179000
    },
    {
      "epoch": 80.60170633138752,
      "grad_norm": 0.3030964732170105,
      "learning_rate": 9.69914683430624e-06,
      "loss": 0.5061,
      "step": 179500
    },
    {
      "epoch": 80.82622361921868,
      "grad_norm": 0.3753713369369507,
      "learning_rate": 9.58688819039066e-06,
      "loss": 0.5057,
      "step": 180000
    },
    {
      "epoch": 81.05074090704984,
      "grad_norm": 0.22749774158000946,
      "learning_rate": 9.47462954647508e-06,
      "loss": 0.506,
      "step": 180500
    },
    {
      "epoch": 81.275258194881,
      "grad_norm": 0.2595929205417633,
      "learning_rate": 9.362370902559497e-06,
      "loss": 0.5059,
      "step": 181000
    },
    {
      "epoch": 81.49977548271217,
      "grad_norm": 0.21858765184879303,
      "learning_rate": 9.250112258643915e-06,
      "loss": 0.5058,
      "step": 181500
    },
    {
      "epoch": 81.72429277054333,
      "grad_norm": 0.22971497476100922,
      "learning_rate": 9.137853614728335e-06,
      "loss": 0.5058,
      "step": 182000
    },
    {
      "epoch": 81.94881005837449,
      "grad_norm": 0.3245510458946228,
      "learning_rate": 9.025594970812754e-06,
      "loss": 0.5059,
      "step": 182500
    },
    {
      "epoch": 82.17332734620565,
      "grad_norm": 0.2883848547935486,
      "learning_rate": 8.913336326897172e-06,
      "loss": 0.5058,
      "step": 183000
    },
    {
      "epoch": 82.39784463403682,
      "grad_norm": 0.2879514694213867,
      "learning_rate": 8.80107768298159e-06,
      "loss": 0.5057,
      "step": 183500
    },
    {
      "epoch": 82.62236192186798,
      "grad_norm": 0.23627623915672302,
      "learning_rate": 8.688819039066007e-06,
      "loss": 0.5059,
      "step": 184000
    },
    {
      "epoch": 82.84687920969915,
      "grad_norm": 0.26841145753860474,
      "learning_rate": 8.576560395150427e-06,
      "loss": 0.5058,
      "step": 184500
    },
    {
      "epoch": 83.07139649753032,
      "grad_norm": 0.2581980228424072,
      "learning_rate": 8.464301751234846e-06,
      "loss": 0.5056,
      "step": 185000
    },
    {
      "epoch": 83.29591378536148,
      "grad_norm": 0.31247153878211975,
      "learning_rate": 8.352043107319264e-06,
      "loss": 0.5057,
      "step": 185500
    },
    {
      "epoch": 83.52043107319264,
      "grad_norm": 0.3078114688396454,
      "learning_rate": 8.239784463403682e-06,
      "loss": 0.5056,
      "step": 186000
    },
    {
      "epoch": 83.7449483610238,
      "grad_norm": 0.23781803250312805,
      "learning_rate": 8.127525819488101e-06,
      "loss": 0.5058,
      "step": 186500
    },
    {
      "epoch": 83.96946564885496,
      "grad_norm": 0.35277944803237915,
      "learning_rate": 8.015267175572519e-06,
      "loss": 0.5058,
      "step": 187000
    },
    {
      "epoch": 84.19398293668613,
      "grad_norm": 0.2868335247039795,
      "learning_rate": 7.903008531656939e-06,
      "loss": 0.5056,
      "step": 187500
    },
    {
      "epoch": 84.41850022451729,
      "grad_norm": 0.29871365427970886,
      "learning_rate": 7.790749887741356e-06,
      "loss": 0.5054,
      "step": 188000
    },
    {
      "epoch": 84.64301751234845,
      "grad_norm": 0.27308064699172974,
      "learning_rate": 7.678491243825776e-06,
      "loss": 0.5056,
      "step": 188500
    },
    {
      "epoch": 84.86753480017961,
      "grad_norm": 0.3031752407550812,
      "learning_rate": 7.5662325999101935e-06,
      "loss": 0.5059,
      "step": 189000
    },
    {
      "epoch": 85.09205208801077,
      "grad_norm": 0.2789762020111084,
      "learning_rate": 7.453973955994611e-06,
      "loss": 0.5056,
      "step": 189500
    },
    {
      "epoch": 85.31656937584194,
      "grad_norm": 0.2611207067966461,
      "learning_rate": 7.341715312079031e-06,
      "loss": 0.5057,
      "step": 190000
    },
    {
      "epoch": 85.5410866636731,
      "grad_norm": 0.24743999540805817,
      "learning_rate": 7.229456668163449e-06,
      "loss": 0.5056,
      "step": 190500
    },
    {
      "epoch": 85.76560395150426,
      "grad_norm": 0.24107900261878967,
      "learning_rate": 7.117198024247868e-06,
      "loss": 0.5056,
      "step": 191000
    },
    {
      "epoch": 85.99012123933542,
      "grad_norm": 0.28490975499153137,
      "learning_rate": 7.004939380332286e-06,
      "loss": 0.5056,
      "step": 191500
    },
    {
      "epoch": 86.21463852716658,
      "grad_norm": 0.3331594467163086,
      "learning_rate": 6.892680736416704e-06,
      "loss": 0.5056,
      "step": 192000
    },
    {
      "epoch": 86.43915581499776,
      "grad_norm": 0.24921195209026337,
      "learning_rate": 6.780422092501124e-06,
      "loss": 0.5054,
      "step": 192500
    },
    {
      "epoch": 86.66367310282892,
      "grad_norm": 0.39464014768600464,
      "learning_rate": 6.6681634485855415e-06,
      "loss": 0.5057,
      "step": 193000
    },
    {
      "epoch": 86.88819039066009,
      "grad_norm": 0.31197047233581543,
      "learning_rate": 6.55590480466996e-06,
      "loss": 0.5055,
      "step": 193500
    },
    {
      "epoch": 87.11270767849125,
      "grad_norm": 0.21911528706550598,
      "learning_rate": 6.443646160754378e-06,
      "loss": 0.5056,
      "step": 194000
    },
    {
      "epoch": 87.33722496632241,
      "grad_norm": 0.38670042157173157,
      "learning_rate": 6.3313875168387965e-06,
      "loss": 0.5057,
      "step": 194500
    },
    {
      "epoch": 87.56174225415357,
      "grad_norm": 0.26228347420692444,
      "learning_rate": 6.219128872923215e-06,
      "loss": 0.5054,
      "step": 195000
    },
    {
      "epoch": 87.78625954198473,
      "grad_norm": 0.2942723035812378,
      "learning_rate": 6.106870229007634e-06,
      "loss": 0.5055,
      "step": 195500
    },
    {
      "epoch": 88.0107768298159,
      "grad_norm": 0.2909410893917084,
      "learning_rate": 5.994611585092052e-06,
      "loss": 0.5054,
      "step": 196000
    },
    {
      "epoch": 88.23529411764706,
      "grad_norm": 0.25176724791526794,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.5055,
      "step": 196500
    },
    {
      "epoch": 88.45981140547822,
      "grad_norm": 0.3334571421146393,
      "learning_rate": 5.7700942972608895e-06,
      "loss": 0.5054,
      "step": 197000
    },
    {
      "epoch": 88.68432869330938,
      "grad_norm": 0.27721381187438965,
      "learning_rate": 5.657835653345308e-06,
      "loss": 0.5054,
      "step": 197500
    },
    {
      "epoch": 88.90884598114054,
      "grad_norm": 0.26026827096939087,
      "learning_rate": 5.545577009429726e-06,
      "loss": 0.5054,
      "step": 198000
    },
    {
      "epoch": 89.1333632689717,
      "grad_norm": 0.26512953639030457,
      "learning_rate": 5.433318365514145e-06,
      "loss": 0.5054,
      "step": 198500
    },
    {
      "epoch": 89.35788055680287,
      "grad_norm": 0.2362801432609558,
      "learning_rate": 5.321059721598563e-06,
      "loss": 0.5053,
      "step": 199000
    },
    {
      "epoch": 89.58239784463403,
      "grad_norm": 0.2560429573059082,
      "learning_rate": 5.208801077682982e-06,
      "loss": 0.5056,
      "step": 199500
    },
    {
      "epoch": 89.8069151324652,
      "grad_norm": 0.34681135416030884,
      "learning_rate": 5.0965424337674e-06,
      "loss": 0.5055,
      "step": 200000
    },
    {
      "epoch": 90.03143242029637,
      "grad_norm": 0.2612685561180115,
      "learning_rate": 4.984283789851819e-06,
      "loss": 0.5054,
      "step": 200500
    },
    {
      "epoch": 90.25594970812753,
      "grad_norm": 0.32256585359573364,
      "learning_rate": 4.8720251459362375e-06,
      "loss": 0.5052,
      "step": 201000
    },
    {
      "epoch": 90.4804669959587,
      "grad_norm": 0.2674732506275177,
      "learning_rate": 4.759766502020656e-06,
      "loss": 0.5053,
      "step": 201500
    },
    {
      "epoch": 90.70498428378986,
      "grad_norm": 0.2618164122104645,
      "learning_rate": 4.647507858105074e-06,
      "loss": 0.5054,
      "step": 202000
    },
    {
      "epoch": 90.92950157162102,
      "grad_norm": 0.29380154609680176,
      "learning_rate": 4.535249214189493e-06,
      "loss": 0.5054,
      "step": 202500
    },
    {
      "epoch": 91.15401885945218,
      "grad_norm": 0.2542499005794525,
      "learning_rate": 4.422990570273911e-06,
      "loss": 0.5054,
      "step": 203000
    },
    {
      "epoch": 91.37853614728334,
      "grad_norm": 0.2614600360393524,
      "learning_rate": 4.31073192635833e-06,
      "loss": 0.5056,
      "step": 203500
    },
    {
      "epoch": 91.6030534351145,
      "grad_norm": 0.2359461933374405,
      "learning_rate": 4.198473282442748e-06,
      "loss": 0.5055,
      "step": 204000
    },
    {
      "epoch": 91.82757072294567,
      "grad_norm": 0.24717122316360474,
      "learning_rate": 4.086214638527167e-06,
      "loss": 0.5052,
      "step": 204500
    },
    {
      "epoch": 92.05208801077683,
      "grad_norm": 0.3364959955215454,
      "learning_rate": 3.9739559946115855e-06,
      "loss": 0.5052,
      "step": 205000
    },
    {
      "epoch": 92.27660529860799,
      "grad_norm": 0.2826927602291107,
      "learning_rate": 3.861697350696003e-06,
      "loss": 0.5052,
      "step": 205500
    },
    {
      "epoch": 92.50112258643915,
      "grad_norm": 0.30830708146095276,
      "learning_rate": 3.749438706780422e-06,
      "loss": 0.5054,
      "step": 206000
    },
    {
      "epoch": 92.72563987427031,
      "grad_norm": 0.2880752682685852,
      "learning_rate": 3.637180062864841e-06,
      "loss": 0.5054,
      "step": 206500
    },
    {
      "epoch": 92.95015716210148,
      "grad_norm": 0.28614526987075806,
      "learning_rate": 3.524921418949259e-06,
      "loss": 0.5051,
      "step": 207000
    },
    {
      "epoch": 93.17467444993264,
      "grad_norm": 0.2836422026157379,
      "learning_rate": 3.412662775033678e-06,
      "loss": 0.5052,
      "step": 207500
    },
    {
      "epoch": 93.39919173776381,
      "grad_norm": 0.3114619255065918,
      "learning_rate": 3.3004041311180963e-06,
      "loss": 0.5054,
      "step": 208000
    },
    {
      "epoch": 93.62370902559498,
      "grad_norm": 0.2288479506969452,
      "learning_rate": 3.1881454872025145e-06,
      "loss": 0.5054,
      "step": 208500
    },
    {
      "epoch": 93.84822631342614,
      "grad_norm": 0.2707577645778656,
      "learning_rate": 3.0758868432869336e-06,
      "loss": 0.5051,
      "step": 209000
    },
    {
      "epoch": 94.0727436012573,
      "grad_norm": 0.26412075757980347,
      "learning_rate": 2.9636281993713517e-06,
      "loss": 0.5051,
      "step": 209500
    },
    {
      "epoch": 94.29726088908846,
      "grad_norm": 0.337453693151474,
      "learning_rate": 2.8513695554557703e-06,
      "loss": 0.5051,
      "step": 210000
    },
    {
      "epoch": 94.52177817691963,
      "grad_norm": 0.2923268675804138,
      "learning_rate": 2.739110911540189e-06,
      "loss": 0.5052,
      "step": 210500
    },
    {
      "epoch": 94.74629546475079,
      "grad_norm": 0.26792824268341064,
      "learning_rate": 2.626852267624607e-06,
      "loss": 0.5052,
      "step": 211000
    },
    {
      "epoch": 94.97081275258195,
      "grad_norm": 0.31203457713127136,
      "learning_rate": 2.5145936237090257e-06,
      "loss": 0.5053,
      "step": 211500
    },
    {
      "epoch": 95.19533004041311,
      "grad_norm": 0.2292151004076004,
      "learning_rate": 2.402334979793444e-06,
      "loss": 0.505,
      "step": 212000
    },
    {
      "epoch": 95.41984732824427,
      "grad_norm": 0.29268112778663635,
      "learning_rate": 2.2900763358778625e-06,
      "loss": 0.5055,
      "step": 212500
    },
    {
      "epoch": 95.64436461607544,
      "grad_norm": 0.2798998951911926,
      "learning_rate": 2.177817691962281e-06,
      "loss": 0.5052,
      "step": 213000
    },
    {
      "epoch": 95.8688819039066,
      "grad_norm": 0.2586117386817932,
      "learning_rate": 2.0655590480466997e-06,
      "loss": 0.5051,
      "step": 213500
    },
    {
      "epoch": 96.09339919173776,
      "grad_norm": 0.2966686189174652,
      "learning_rate": 1.953300404131118e-06,
      "loss": 0.505,
      "step": 214000
    },
    {
      "epoch": 96.31791647956892,
      "grad_norm": 0.2677994966506958,
      "learning_rate": 1.8410417602155368e-06,
      "loss": 0.5051,
      "step": 214500
    },
    {
      "epoch": 96.54243376740008,
      "grad_norm": 0.3596595823764801,
      "learning_rate": 1.7287831162999551e-06,
      "loss": 0.5052,
      "step": 215000
    },
    {
      "epoch": 96.76695105523125,
      "grad_norm": 0.29661208391189575,
      "learning_rate": 1.6165244723843738e-06,
      "loss": 0.5052,
      "step": 215500
    },
    {
      "epoch": 96.99146834306242,
      "grad_norm": 0.30571243166923523,
      "learning_rate": 1.5042658284687921e-06,
      "loss": 0.5054,
      "step": 216000
    },
    {
      "epoch": 97.21598563089358,
      "grad_norm": 0.3348713517189026,
      "learning_rate": 1.3920071845532105e-06,
      "loss": 0.5051,
      "step": 216500
    },
    {
      "epoch": 97.44050291872475,
      "grad_norm": 0.32961133122444153,
      "learning_rate": 1.2797485406376292e-06,
      "loss": 0.5051,
      "step": 217000
    },
    {
      "epoch": 97.66502020655591,
      "grad_norm": 0.24694184958934784,
      "learning_rate": 1.1674898967220475e-06,
      "loss": 0.505,
      "step": 217500
    },
    {
      "epoch": 97.88953749438707,
      "grad_norm": 0.32003211975097656,
      "learning_rate": 1.0552312528064662e-06,
      "loss": 0.505,
      "step": 218000
    },
    {
      "epoch": 98.11405478221823,
      "grad_norm": 0.25242242217063904,
      "learning_rate": 9.429726088908848e-07,
      "loss": 0.5052,
      "step": 218500
    },
    {
      "epoch": 98.3385720700494,
      "grad_norm": 0.27951323986053467,
      "learning_rate": 8.307139649753032e-07,
      "loss": 0.5049,
      "step": 219000
    },
    {
      "epoch": 98.56308935788056,
      "grad_norm": 0.24780690670013428,
      "learning_rate": 7.184553210597216e-07,
      "loss": 0.505,
      "step": 219500
    },
    {
      "epoch": 98.78760664571172,
      "grad_norm": 0.22514261305332184,
      "learning_rate": 6.0619667714414e-07,
      "loss": 0.5053,
      "step": 220000
    },
    {
      "epoch": 99.01212393354288,
      "grad_norm": 0.3216713070869446,
      "learning_rate": 4.939380332285587e-07,
      "loss": 0.5051,
      "step": 220500
    },
    {
      "epoch": 99.23664122137404,
      "grad_norm": 0.29504865407943726,
      "learning_rate": 3.816793893129771e-07,
      "loss": 0.5051,
      "step": 221000
    },
    {
      "epoch": 99.4611585092052,
      "grad_norm": 0.27833864092826843,
      "learning_rate": 2.694207453973956e-07,
      "loss": 0.505,
      "step": 221500
    },
    {
      "epoch": 99.68567579703637,
      "grad_norm": 0.29742828011512756,
      "learning_rate": 1.571621014818141e-07,
      "loss": 0.5051,
      "step": 222000
    },
    {
      "epoch": 99.91019308486753,
      "grad_norm": 0.27047449350357056,
      "learning_rate": 4.49034575662326e-08,
      "loss": 0.5048,
      "step": 222500
    }
  ],
  "logging_steps": 500,
  "max_steps": 222700,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 400000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.263238754909184e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
